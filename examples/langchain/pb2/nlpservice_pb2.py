# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: nlpservice.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


import bidistreamingtokenclassificationtaskrequest_pb2 as bidistreamingtokenclassificationtaskrequest__pb2
import classificationresults_pb2 as classificationresults__pb2
import generatedtextresult_pb2 as generatedtextresult__pb2
import generatedtextstreamresult_pb2 as generatedtextstreamresult__pb2
import serverstreamingtextgenerationtaskrequest_pb2 as serverstreamingtextgenerationtaskrequest__pb2
import textclassificationtaskrequest_pb2 as textclassificationtaskrequest__pb2
import textgenerationtaskrequest_pb2 as textgenerationtaskrequest__pb2
import tokenclassificationresults_pb2 as tokenclassificationresults__pb2
import tokenclassificationstreamresult_pb2 as tokenclassificationstreamresult__pb2
import tokenclassificationtaskrequest_pb2 as tokenclassificationtaskrequest__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x10nlpservice.proto\x12\x12\x63\x61ikit.runtime.Nlp\x1a\x31\x62idistreamingtokenclassificationtaskrequest.proto\x1a\x1b\x63lassificationresults.proto\x1a\x19generatedtextresult.proto\x1a\x1fgeneratedtextstreamresult.proto\x1a.serverstreamingtextgenerationtaskrequest.proto\x1a#textclassificationtaskrequest.proto\x1a\x1ftextgenerationtaskrequest.proto\x1a tokenclassificationresults.proto\x1a%tokenclassificationstreamresult.proto\x1a$tokenclassificationtaskrequest.proto2\xdd\x05\n\nNlpService\x12v\n\x19TextGenerationTaskPredict\x12-.caikit.runtime.Nlp.TextGenerationTaskRequest\x1a*.caikit_data_model.nlp.GeneratedTextResult\x12\x9c\x01\n(ServerStreamingTextGenerationTaskPredict\x12<.caikit.runtime.Nlp.ServerStreamingTextGenerationTaskRequest\x1a\x30.caikit_data_model.nlp.GeneratedTextStreamResult0\x01\x12\x87\x01\n\x1eTokenClassificationTaskPredict\x12\x32.caikit.runtime.Nlp.TokenClassificationTaskRequest\x1a\x31.caikit_data_model.nlp.TokenClassificationResults\x12\xaa\x01\n+BidiStreamingTokenClassificationTaskPredict\x12?.caikit.runtime.Nlp.BidiStreamingTokenClassificationTaskRequest\x1a\x36.caikit_data_model.nlp.TokenClassificationStreamResult(\x01\x30\x01\x12\x80\x01\n\x1dTextClassificationTaskPredict\x12\x31.caikit.runtime.Nlp.TextClassificationTaskRequest\x1a,.caikit_data_model.nlp.ClassificationResultsb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'nlpservice_pb2', _globals)
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  _globals['_NLPSERVICE']._serialized_start=410
  _globals['_NLPSERVICE']._serialized_end=1143
# @@protoc_insertion_point(module_scope)
